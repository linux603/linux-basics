




Why NFS ???  

note:  its just for understanding purpose  (starting)
=========

Imagine a real application environment:

---> In real applications, users do NOT talk to one fixed server. They talk to a Load Balancer (LB).

=====

User Browser
     |
Load Balancer
     |
-----------------
|    |     |    |  
web1 web2 web3 web4  

---> Each request can go to a different backend web server
=====

 What Happens During File Uploads & App Operations (Without NFS) ??? 

 note:  Load balancer distributes requests, Each server has its own local disk, No shared filesystem

Important Rule:
Local disks are isolated — same path ≠ same data in each web server 


 Problem 1: Application Uploads Break

 What Happens

1. User uploads a file: data.txt
2. Load balancer sends upload request to web2
3. Application saves file to: web2:/appdata/uploads/data.txt
   
----> Critical Point :

 File is stored on web2’s local filesystem

 Other servers:
  web3:/appdata/uploads → EMPTY
  web4:/appdata/uploads → EMPTY
  
----> Next User Action

User refreshes page / clicks download / views profile.

This is a new HTTP request

Load balancer may send it to web3 or web4.

----> Result

Application looks for: /appdata/uploads/data.txt

But file does not exist on that server  (web3 or web4).

File not found
Broken user experience

----> Business Impact

 Users complain
 Upload feature unreliable
 Support tickets increase


Problem 2: Logs Are Split Across Servers

 ---> What Happens

Each server writes logs locally:

web2:/var/log/app.log
web3:/var/log/app.log
web4:/var/log/app.log

---> Why This Is a Problem

 A single user request may hit multiple servers
 Logs for one transaction are scattered
 No complete visibility


 ---> Impact

 Root cause analysis takes hours
 Production issues stay unresolved longer
 SLA violations


Problem 3: Application Binaries Drift

 ---> What Happens

Application deployed manually:

/opt/myapp

Versions across servers:

| Server | Version |
| ------ | ------- |
| web2   | v1.2    |
| web3   | v1.1    |
| web4   | v1.0    |


---> Why This Happens

 Manual deployments
 Missed updates
 Failed copy on one server


 ---> Result

 Random bugs
 Inconsistent behavior
 “Works on web2, fails on web4”

---> Very hard to debug


---> Business Impact

 Loss of trust
 Frequent rollbacks
 Deployment fear

 Problem 4: Manual Sync Is Not Scalable

 Tools Used

scp
rsync
cron jobs



 Hidden Problems

| Issue           | Explanation               |
| --------------- | ------------------------- |
| Race conditions | File accessed during copy |
| Partial sync    | Network breaks mid-copy   |
| Performance     | Heavy IO + network        |
| Human error     | Wrong path, wrong server  |


Works for 2 servers, fails for 10+ servers


 Problem 5: Scaling Becomes Painful

 Scenario: Add a New Server

web5

 ---> Required Manual Work

 Copy app binaries
 Sync uploads
 Fix permissions
 Verify data consistency
 Test manually


 ---> Why This Is Bad

 Scaling takes hours/days
 High chance of mistakes
 Delays business growth



The NFS Solution (What Changes)

            NFS Server (m1)
               |
           /appdata
               |
--------------------------------
|      |      |      |         |
m2     m3     m4     m5        m6

All app servers mount:  /appdata  → SAME DATA


Problem 1 Solved: Uploads Work Everywhere
Problem 2 Solved: Centralized Logs
Problem 3 Solved: Consistent Binaries
Problem 4 Solved: No Manual Sync
Problem 5 Solved: Easy Backup
Problem 6 Solved: Easy Scaling


note: to this its just for understanding purpose (ending )
=========


 NFS Concept :
============

| Term       | Meaning                              |
-----------------------------------------------------
| NFS Server | Machine that shares storage          |
| NFS Client | Machine that uses shared storage     |
| Export     | Directory shared by NFS server       |
| Mount      | Attaching remote directory locally   |

  NFS makes remote storage look like local storage



